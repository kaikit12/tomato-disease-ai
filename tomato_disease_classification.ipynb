{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3d845",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# TO√ÄN B·ªò M√É NGU·ªíN - PHI√äN B·∫¢N T√çCH H·ª¢P GEMINI VISION (S·ª¨A L·ªñI MODEL)\n",
    "# =================================================================\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PH·∫¶N 1: C√ÄI ƒê·∫∂T V√Ä CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG\n",
    "# -----------------------------------------------------------------\n",
    "print(\"B·∫Øt ƒë·∫ßu qu√° tr√¨nh c√†i ƒë·∫∑t v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng...\")\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        package_name = package.split('==')[0].replace('-', '_')\n",
    "        __import__(package_name)\n",
    "        print(f\"‚úÖ {package} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.\")\n",
    "    except ImportError:\n",
    "        print(f\"‚è≥ ƒêang c√†i ƒë·∫∑t {package}...\")\n",
    "        subprocess.run(f\"pip install --upgrade --no-cache-dir {package} -q\", shell=True, check=True)\n",
    "        print(f\"‚úÖ {package} ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng.\")\n",
    "\n",
    "for pkg in ['streamlit', 'pyngrok', 'tensorflow==2.15.0', 'streamlit-image-comparison', 'groq', 'google-generativeai']:\n",
    "    install_if_missing(pkg)\n",
    "\n",
    "from pyngrok import ngrok\n",
    "print(\"üîÑ ƒêang ng·∫Øt c√°c k·∫øt n·ªëi ngrok c≈©...\")\n",
    "ngrok.kill()\n",
    "\n",
    "print(\"üîó ƒêang k·∫øt n·ªëi v·ªõi Google Drive...\")\n",
    "try:\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    print(\"‚úÖ K·∫øt n·ªëi Google Drive th√†nh c√¥ng.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi k·∫øt n·ªëi Google Drive: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PH·∫¶N 2: VI·∫æT M√É ·ª®NG D·ª§NG STREAMLIT V√ÄO FILE app.py\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üìù ƒêang ghi m√£ ngu·ªìn c·ªßa ·ª©ng d·ª•ng v√†o file app.py...\")\n",
    "\n",
    "app_code = '''\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import io\n",
    "from streamlit_image_comparison import image_comparison\n",
    "from groq import Groq\n",
    "from datetime import datetime\n",
    "import google.generativeai as genai\n",
    "\n",
    "st.set_page_config(page_title=\"Tr·ª£ l√Ω C√† chua AI\", page_icon=\"üçÖ\", layout=\"wide\")\n",
    "\n",
    "GROQ_API_KEY = os.environ.get('GROQ_API_KEY')\n",
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "else:\n",
    "    groq_client = None\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "else:\n",
    "    st.error(\"‚ö†Ô∏è Google API Key ch∆∞a ƒë∆∞·ª£c cung c·∫•p. T√≠nh nƒÉng ki·ªÉm tra ch√©o s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.\")\n",
    "\n",
    "DISEASE_LIBRARY = {\n",
    "    'B·ªánh: Nh·ªán ƒë·ªè (spider mites)': {'description': 'Nh·ªán ƒë·ªè r·∫•t nh·ªè, s·ªëng ·ªü m·∫∑t d∆∞·ªõi l√°, h√∫t nh·ª±a c√¢y, l√†m l√° c√≥ ƒë·ªëm v√†ng, b·∫°c.', 'symptoms': '- L√° c√≥ ch·∫•m li ti v√†ng/tr·∫Øng.\\\\n- C√≥ th·ªÉ c√≥ m·∫°ng nh·ªán m·ªãn m·∫∑t d∆∞·ªõi l√°.'},\n",
    "    'B·ªánh: S∆∞∆°ng mai (late blight)': {'description': 'B·ªánh nguy hi·ªÉm do n·∫•m, ph√°t tri·ªÉn m·∫°nh khi ·∫©m, m√°t.', 'symptoms': '- ƒê·ªëm xanh x√°m, √∫ng n∆∞·ªõc tr√™n l√°.\\\\n- V·∫øt b·ªánh lan nhanh, chuy·ªÉn m√†u n√¢u ƒëen.'},\n",
    "    'L√° kh·ªèe m·∫°nh': {'description': 'L√° kh√¥ng c√≥ d·∫•u hi·ªáu b·ªánh, m√†u xanh ƒë·ªÅu.', 'symptoms': '- B·ªÅ m·∫∑t l√° nh·∫µn, kh√¥ng ƒë·ªëm, m·ªëc.\\\\n- M√†u s·∫Øc xanh t∆∞∆°i.'}\n",
    "}\n",
    "\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state.history = []\n",
    "\n",
    "@st.cache_resource\n",
    "def load_keras_model():\n",
    "    model_path = \"/content/drive/My Drive/BaocaoPython/DATASET/keras_model.h5\"\n",
    "    if not os.path.exists(model_path): st.error(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh t·∫°i {model_path}.\"); st.stop()\n",
    "    def custom_depthwise_conv2d(*args, **kwargs): kwargs.pop('groups', None); return tf.keras.layers.DepthwiseConv2D(*args, **kwargs)\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, custom_objects={'DepthwiseConv2D': custom_depthwise_conv2d}, compile=False)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    except Exception as e: st.error(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}\"); st.stop()\n",
    "\n",
    "model = load_keras_model()\n",
    "class_names = ['B·ªánh: Nh·ªán ƒë·ªè (spider mites)', 'B·ªánh: S∆∞∆°ng mai (late blight)', 'B·ªánh: ƒê·ªëm m·ª•c ti√™u (target spot)', 'L√° kh·ªèe m·∫°nh', 'B·ªánh: QuƒÉn l√° (leaf curl)', 'B·ªánh: ƒê·ªëm septoria', 'B·ªánh: M·ªëc l√° (leaf mold)', 'B·ªánh: S∆∞∆°ng mai s·ªõm (early blight)']\n",
    "\n",
    "def predict_image(image):\n",
    "    img = load_img(image, target_size=(224, 224)); img_array = img_to_array(img) / 127.5 - 1\n",
    "    img_array = np.expand_dims(img_array, axis=0); predictions = model.predict(img_array)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]; confidence = np.max(predictions[0]) * 100\n",
    "    return predicted_class, confidence, predictions[0]\n",
    "\n",
    "def draw_result(image_file, result_text, confidence):\n",
    "    image = Image.open(image_file).convert(\"RGB\"); draw = ImageDraw.Draw(image)\n",
    "    try: font = ImageFont.truetype(\"arial.ttf\", 30)\n",
    "    except IOError: font = ImageFont.load_default()\n",
    "    text = f\"{result_text} ({confidence:.2f}%)\"; text_bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]; text_height = text_bbox[3] - text_bbox[1]\n",
    "    draw.rectangle([(10, 10), (10 + text_width + 20, 10 + text_height + 20)], fill=\"rgba(0,0,0,128)\")\n",
    "    draw.text((20, 20), text, fill=\"white\", font=font); return image\n",
    "\n",
    "@st.cache_data\n",
    "def get_treatment_suggestion(disease_name: str) -> str:\n",
    "    if not groq_client: return \"‚ö†Ô∏è Vui l√≤ng cung c·∫•p Groq API Key ƒë·ªÉ d√πng t√≠nh nƒÉng n√†y.\"\n",
    "    if disease_name == 'L√° kh·ªèe m·∫°nh': return \"‚úÖ Tuy·ªát v·ªùi! L√° c√¢y c·ªßa b·∫°n kh·ªèe m·∫°nh.\"\n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(model=\"llama-3.1-8b-instant\", messages=[{\"role\": \"system\", \"content\": \"B·∫°n l√† chuy√™n gia n√¥ng nghi·ªáp Vi·ªát Nam, t∆∞ v·∫•n c√°ch tr·ªã b·ªánh c√† chua ng·∫Øn g·ªçn cho n√¥ng d√¢n.\"}, {\"role\": \"user\", \"content\": f\"C√¢y c√† chua c·ªßa t√¥i b·ªã '{disease_name}'. ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p tr·ªã v√† ph√≤ng b·ªánh.\"}], temperature=0.7, max_tokens=500)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e: return f\"‚ùå L·ªói API t∆∞ v·∫•n: {e}\"\n",
    "\n",
    "def get_vision_ai_check(image_bytes: bytes) -> str:\n",
    "    if not GOOGLE_API_KEY:\n",
    "        return \"‚ö†Ô∏è Vui l√≤ng cung c·∫•p Google API Key ƒë·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.\"\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "        # <<<<<<<<<<<<<<<< ƒê√É THAY ƒê·ªîI T√äN MODEL T·∫†I ƒê√ÇY >>>>>>>>>>>>>>>>\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "\n",
    "        prompt_parts = [\n",
    "            \"B·∫°n l√† m·ªôt chuy√™n gia ch·∫©n ƒëo√°n b·ªánh c√¢y tr·ªìng qua h√¨nh ·∫£nh. H√£y ph√¢n t√≠ch k·ªπ l∆∞·ª°ng ·∫£nh l√° c√† chua n√†y.\\\\n\",\n",
    "            \"1. Ch·∫©n ƒëo√°n xem l√° c√¢y b·ªã b·ªánh g√¨ ho·∫∑c l√† l√° kh·ªèe m·∫°nh.\\\\n\",\n",
    "            \"2. Li·ªát k√™ c√°c tri·ªáu ch·ª©ng c·ª• th·ªÉ b·∫°n nh√¨n th·∫•y tr√™n l√° (v√≠ d·ª•: ƒë·ªëm v√†ng, vi·ªÅn n√¢u, l√° quƒÉn...).\\\\n\",\n",
    "            \"3. ƒê∆∞a ra k·∫øt lu·∫≠n m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch.\\\\n\\\\n\",\n",
    "            img,\n",
    "        ]\n",
    "\n",
    "        response = model.generate_content(prompt_parts)\n",
    "        return f\"**ƒê√°nh gi√° t·ª´ Google Gemini Vision:**\\\\n\\\\n\" + response.text\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå L·ªói khi g·ªçi API Google Gemini Vision: {e}\"\n",
    "\n",
    "st.title(\"üçÖ Tr·ª£ l√Ω C√† chua AI (T√≠ch h·ª£p Gemini Vision)\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"üìñ Th∆∞ vi·ªán b·ªánh h·ªçc\"); selected_disease = st.selectbox(\"Tra c·ª©u th√¥ng tin b·ªánh:\", list(DISEASE_LIBRARY.keys()))\n",
    "    if selected_disease: info = DISEASE_LIBRARY[selected_disease]; st.subheader(selected_disease); st.markdown(f\"**M√¥ t·∫£:** {info['description']}\"); st.markdown(f\"**Tri·ªáu ch·ª©ng:**\\\\n{info['symptoms']}\")\n",
    "    st.markdown(\"---\"); st.header(\"üìú L·ªãch s·ª≠ nh·∫≠n di·ªán\")\n",
    "    if not st.session_state.history: st.info(\"Ch∆∞a c√≥ l·ªãch s·ª≠ n√†o.\")\n",
    "    else:\n",
    "        for i in range(len(st.session_state.history) - 1, -1, -1):\n",
    "            record = st.session_state.history[i]; col1, col2 = st.columns([4, 1])\n",
    "            with col1:\n",
    "                with st.expander(f\"{record['prediction']} ({record['time']})\"): st.image(record['image'], width=100); st.write(f\"ƒê·ªô tin c·∫≠y: {record['confidence']:.2f}%\")\n",
    "            with col2:\n",
    "                if st.button(\"üóëÔ∏è\", key=f\"delete_{i}_{record['time']}\", help=\"X√≥a m·ª•c n√†y\"): del st.session_state.history[i]; st.rerun()\n",
    "\n",
    "col1, col2 = st.columns([2, 3])\n",
    "with col1:\n",
    "    st.subheader(\"‚ë† T·∫£i ho·∫∑c Ch·ª•p ·∫£nh\"); uploaded_file = st.file_uploader(\"T·∫£i ·∫£nh t·ª´ thi·∫øt b·ªã:\", type=[\"jpg\", \"jpeg\", \"png\"]); camera_file = st.camera_input(\"Ch·ª•p ·∫£nh t·ª´ camera:\")\n",
    "    image_to_process = camera_file or uploaded_file\n",
    "    if image_to_process: st.image(image_to_process, caption=\"·∫¢nh ƒë∆∞·ª£c ch·ªçn\", use_container_width=True)\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"‚ë° Xem k·∫øt qu·∫£ ph√¢n t√≠ch\")\n",
    "    if image_to_process:\n",
    "        with st.spinner(\"‚è≥ AI ƒëang ph√¢n t√≠ch, vui l√≤ng ch·ªù...\"):\n",
    "            predicted_class, confidence, probabilities = predict_image(image_to_process)\n",
    "            result_image = draw_result(image_to_process, predicted_class, confidence)\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\"); new_record = {\"image\": image_to_process.getvalue(), \"prediction\": predicted_class, \"confidence\": confidence, \"time\": current_time}\n",
    "        if not st.session_state.history or st.session_state.history[-1]['prediction'] != new_record['prediction']: st.session_state.history.append(new_record)\n",
    "        if len(st.session_state.history) > 10: st.session_state.history.pop(0)\n",
    "\n",
    "        tabs = st.tabs([\"üìä K·∫øt qu·∫£ ch√≠nh\", \"‚ÜîÔ∏è So s√°nh ·∫£nh\", \"üßë‚Äçüåæ T∆∞ v·∫•n AI (Groq)\", \"üîç Ki·ªÉm tra ch√©o (Gemini)\"])\n",
    "        with tabs[0]:\n",
    "            st.metric(\"Ch·∫©n ƒëo√°n (Model T·ª± hu·∫•n luy·ªán)\", predicted_class); st.metric(\"ƒê·ªô tin c·∫≠y\", f\"{confidence:.2f}%\"); st.markdown(\"---\"); st.markdown(\"##### Ph√¢n b·ªï x√°c su·∫•t:\")\n",
    "            for cls, prob in zip(class_names, probabilities): st.write(f\"{cls}: {prob*100:.2f}%\"); st.progress(float(prob))\n",
    "            buf = io.BytesIO(); result_image.save(buf, format=\"PNG\"); st.download_button(\"‚¨áÔ∏è T·∫£i ·∫£nh k·∫øt qu·∫£\", buf.getvalue(), \"ket_qua.png\", \"image/png\")\n",
    "        with tabs[1]:\n",
    "            st.markdown(\"K√©o thanh tr∆∞·ª£t ƒë·ªÉ so s√°nh.\"); image_comparison(Image.open(image_to_process), result_image, \"·∫¢nh g·ªëc\", \"·∫¢nh c√≥ ch·∫©n ƒëo√°n\")\n",
    "        with tabs[2]:\n",
    "            st.info(\"Nh·∫≠n g·ª£i √Ω chi ti·∫øt t·ª´ AI LLaMA 3.1 qua Groq.\");\n",
    "            if st.button(\"üí° Nh·∫≠n g·ª£i √Ω tr·ªã b·ªánh\"):\n",
    "                with st.spinner(\"ü§ñ Groq AI ƒëang so·∫°n th·∫£o...\"): st.markdown(get_treatment_suggestion(predicted_class))\n",
    "        with tabs[3]:\n",
    "            st.info(\"S·ª≠ d·ª•ng Google Gemini Vision ƒë·ªÉ c√≥ th√™m g√≥c nh√¨n th·ª© hai.\");\n",
    "            if st.button(\"üî¨ B·∫Øt ƒë·∫ßu ki·ªÉm tra ch√©o v·ªõi Gemini\"):\n",
    "                with st.spinner(\"üõ∞Ô∏è Gemini Vision ƒëang ph√¢n t√≠ch ·∫£nh...\"): st.markdown(get_vision_ai_check(image_to_process.getvalue()))\n",
    "    else: st.info(\"üëà Vui l√≤ng t·∫£i ·∫£nh l√™n ho·∫∑c s·ª≠ d·ª•ng camera ƒë·ªÉ b·∫Øt ƒë·∫ßu.\")\n",
    "'''\n",
    "\n",
    "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(app_code)\n",
    "print(\"‚úÖ ƒê√£ t·∫°o file app.py th√†nh c√¥ng.\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PH·∫¶N 3: CH·∫†Y ·ª®NG D·ª§NG\n",
    "# -----------------------------------------------------------------\n",
    "print(\"üöÄ ƒêang kh·ªüi ch·∫°y ·ª©ng d·ª•ng Streamlit v√† t·∫°o ƒë∆∞·ªùng link c√¥ng khai...\")\n",
    "\n",
    "# ========================>   THAY TH√îNG TIN C·ª¶A B·∫†N T·∫†I ƒê√ÇY   <========================\n",
    "GROQ_API_KEY = \"YOUR_GROQ_API_KEY_HERE\"\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n",
    "\n",
    "GOOGLE_API_KEY = \"YOUR_GOOGLE_API_KEY_HERE\"\n",
    "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY\n",
    "\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\" # V√≠ d·ª•: \"2fA...\"\n",
    "# ======================================================================================\n",
    "\n",
    "if \"YOUR_NGROK\" in NGROK_AUTH_TOKEN:\n",
    "    print(\"‚ùå L·ªñI: B·∫°n ph·∫£i cung c·∫•p Ngrok Authtoken ƒë·ªÉ ch·∫°y ·ª©ng d·ª•ng.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "os.system('streamlit run app.py &')\n",
    "time.sleep(10)\n",
    "\n",
    "try:\n",
    "    public_url = ngrok.connect(8501, proto='http')\n",
    "    print(\"üéâüéâüéâ ·ª®ng d·ª•ng c·ªßa b·∫°n ƒë√£ s·∫µn s√†ng! üéâüéâüéâ\")\n",
    "    print(f\"üëâ Truy c·∫≠p t·∫°i ƒë√¢y: {public_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫°o tunnel ngrok: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    while True: time.sleep(3600)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüëã ƒê√£ d·ª´ng ·ª©ng d·ª•ng.\")\n",
    "    ngrok.kill()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
