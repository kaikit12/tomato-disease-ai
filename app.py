import streamlit as st
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np
import os
from PIL import Image, ImageDraw, ImageFont
import io
from streamlit_image_comparison import image_comparison
from groq import Groq
from datetime import datetime
import google.generativeai as genai

st.set_page_config(page_title="Tr·ª£ l√Ω C√† chua AI", page_icon="üçÖ", layout="wide")

# API Keys t·ª´ Streamlit Secrets v·ªõi error handling
try:
    GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")
except Exception as e:
    st.error(f"‚ùå L·ªói ƒë·ªçc secrets: {e}")
    GROQ_API_KEY = ""
    GOOGLE_API_KEY = ""

# Initialize Groq client v·ªõi error handling
groq_client = None
if GROQ_API_KEY and GROQ_API_KEY.strip():
    try:
        groq_client = Groq(api_key=GROQ_API_KEY.strip())
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói Groq: {e}")
        groq_client = None
else:
    st.sidebar.warning("‚ö†Ô∏è Groq API ch∆∞a c·∫•u h√¨nh")

# Initialize Google AI v·ªõi error handling
if GOOGLE_API_KEY and GOOGLE_API_KEY.strip():
    try:
        genai.configure(api_key=GOOGLE_API_KEY.strip())
    except Exception as e:
        st.sidebar.error(f"‚ùå L·ªói Google AI: {e}")
else:
    st.sidebar.warning("‚ö†Ô∏è Google API ch∆∞a c·∫•u h√¨nh")

DISEASE_LIBRARY = {
    'B·ªánh: Nh·ªán ƒë·ªè (spider mites)': {
        'description': 'Nh·ªán ƒë·ªè r·∫•t nh·ªè, s·ªëng ·ªü m·∫∑t d∆∞·ªõi l√°, h√∫t nh·ª±a c√¢y, l√†m l√° c√≥ ƒë·ªëm v√†ng, b·∫°c.',
        'symptoms': '- L√° c√≥ ch·∫•m li ti v√†ng/tr·∫Øng.\n- C√≥ th·ªÉ c√≥ m·∫°ng nh·ªán m·ªãn m·∫∑t d∆∞·ªõi l√°.'
    },
    'B·ªánh: S∆∞∆°ng mai (late blight)': {
        'description': 'B·ªánh nguy hi·ªÉm do n·∫•m, ph√°t tri·ªÉn m·∫°nh khi ·∫©m, m√°t.',
        'symptoms': '- ƒê·ªëm xanh x√°m, √∫ng n∆∞·ªõc tr√™n l√°.\n- V·∫øt b·ªánh lan nhanh, chuy·ªÉn m√†u n√¢u ƒëen.'
    },
    'B·ªánh: ƒê·ªëm m·ª•c ti√™u (target spot)': {
        'description': 'B·ªánh do n·∫•m g√¢y ra, t·∫°o th√†nh c√°c ƒë·ªëm tr√≤n c√≥ v√≤ng tr√≤n ƒë·ªìng t√¢m.',
        'symptoms': '- ƒê·ªëm tr√≤n m√†u n√¢u c√≥ v√≤ng tr√≤n.\n- L√° v√†ng v√† r·ª•ng s·ªõm.'
    },
    'L√° kh·ªèe m·∫°nh': {
        'description': 'L√° kh√¥ng c√≥ d·∫•u hi·ªáu b·ªánh, m√†u xanh ƒë·ªÅu.',
        'symptoms': '- B·ªÅ m·∫∑t l√° nh·∫µn, kh√¥ng ƒë·ªëm, m·ªëc.\n- M√†u s·∫Øc xanh t∆∞∆°i.'
    },
    'B·ªánh: QuƒÉn l√° (leaf curl)': {
        'description': 'B·ªánh do virus g√¢y ra, l√†m l√° quƒÉn cong v√† bi·∫øn d·∫°ng.',
        'symptoms': '- L√° quƒÉn cong b·∫•t th∆∞·ªùng.\n- M√†u l√° nh·∫°t, v√†ng √∫a.'
    },
    'B·ªánh: ƒê·ªëm septoria': {
        'description': 'B·ªánh do n·∫•m Septoria lycopersici, th∆∞·ªùng xu·∫•t hi·ªán ·ªü l√° gi√†.',
        'symptoms': '- ƒê·ªëm tr√≤n nh·ªè m√†u x√°m v·ªõi vi·ªÅn ƒëen.\n- L√° v√†ng v√† r·ª•ng t·ª´ d∆∞·ªõi l√™n.'
    },
    'B·ªánh: M·ªëc l√° (leaf mold)': {
        'description': 'B·ªánh do n·∫•m, ph√°t tri·ªÉn trong ƒëi·ªÅu ki·ªán ·∫©m ∆∞·ªõt.',
        'symptoms': '- L·ªõp m·ªëc v√†ng ·ªü m·∫∑t d∆∞·ªõi l√°.\n- L√° h√©o v√† ch·∫øt d·∫ßn.'
    },
    'B·ªánh: S∆∞∆°ng mai s·ªõm (early blight)': {
        'description': 'B·ªánh do n·∫•m Alternaria solani, ·∫£nh h∆∞·ªüng ƒë·∫øn l√° v√† qu·∫£.',
        'symptoms': '- ƒê·ªëm n√¢u c√≥ v√≤ng tr√≤n ƒë·ªìng t√¢m.\n- L√° v√†ng v√† r·ª•ng s·ªõm.'
    }
}

if 'history' not in st.session_state:
    st.session_state.history = []

@st.cache_resource
def load_keras_model():
    """Load model t·ª´ GitHub ho·∫∑c local"""
    # Thay ƒë·ªïi path model cho production
    model_path = "models/keras_model.h5"
    
    # Check if model exists before loading
    if not os.path.exists(model_path):
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh t·∫°i {model_path}")
        st.info("üí° Vui l√≤ng upload file model v√†o th∆∞ m·ª•c 'models/' v·ªõi t√™n 'keras_model.h5'")
        st.stop()
    
    def custom_depthwise_conv2d(*args, **kwargs):
        kwargs.pop('groups', None)
        return tf.keras.layers.DepthwiseConv2D(*args, **kwargs)
    
    try:
        model = tf.keras.models.load_model(
            model_path, 
            custom_objects={'DepthwiseConv2D': custom_depthwise_conv2d}, 
            compile=False
        )
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        return model
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        st.stop()

# Ch·ªâ load model khi c√≥ file
if os.path.exists("models/keras_model.h5"):
    model = load_keras_model()
    class_names = [
        'B·ªánh: Nh·ªán ƒë·ªè (spider mites)', 
        'B·ªánh: S∆∞∆°ng mai (late blight)', 
        'B·ªánh: ƒê·ªëm m·ª•c ti√™u (target spot)', 
        'L√° kh·ªèe m·∫°nh', 
        'B·ªánh: QuƒÉn l√° (leaf curl)', 
        'B·ªánh: ƒê·ªëm septoria', 
        'B·ªánh: M·ªëc l√° (leaf mold)', 
        'B·ªánh: S∆∞∆°ng mai s·ªõm (early blight)'
    ]
else:
    model = None
    st.error("‚ùå Model ch∆∞a ƒë∆∞·ª£c upload. Vui l√≤ng th√™m file 'keras_model.h5' v√†o th∆∞ m·ª•c 'models/'")

def predict_image(image):
    if model is None:
        return "Model ch∆∞a ƒë∆∞·ª£c t·∫£i", 0, []
    
    img = load_img(image, target_size=(224, 224))
    img_array = img_to_array(img) / 127.5 - 1
    img_array = np.expand_dims(img_array, axis=0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = np.max(predictions[0]) * 100
    return predicted_class, confidence, predictions[0]

def draw_result(image_file, result_text, confidence):
    image = Image.open(image_file).convert("RGB")
    draw = ImageDraw.Draw(image)
    
    try:
        font = ImageFont.truetype("arial.ttf", 30)
    except IOError:
        font = ImageFont.load_default()
    
    text = f"{result_text} ({confidence:.2f}%)"
    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]
    
    draw.rectangle([(10, 10), (10 + text_width + 20, 10 + text_height + 20)], fill="rgba(0,0,0,128)")
    draw.text((20, 20), text, fill="white", font=font)
    return image

@st.cache_data
def get_treatment_suggestion(disease_name: str) -> str:
    if not groq_client:
        return "‚ö†Ô∏è Groq API ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ho·∫∑c c√≥ l·ªói k·∫øt n·ªëi."
    
    if disease_name == 'L√° kh·ªèe m·∫°nh':
        return "‚úÖ Tuy·ªát v·ªùi! L√° c√¢y c·ªßa b·∫°n kh·ªèe m·∫°nh."
    
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": "B·∫°n l√† chuy√™n gia n√¥ng nghi·ªáp Vi·ªát Nam, t∆∞ v·∫•n c√°ch tr·ªã b·ªánh c√† chua ng·∫Øn g·ªçn cho n√¥ng d√¢n."},
                {"role": "user", "content": f"C√¢y c√† chua c·ªßa t√¥i b·ªã '{disease_name}'. ƒê·ªÅ xu·∫•t ph∆∞∆°ng ph√°p tr·ªã v√† ph√≤ng b·ªánh."}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"‚ùå L·ªói API t∆∞ v·∫•n: {str(e)}"

def get_vision_ai_check(image_bytes: bytes) -> str:
    if not GOOGLE_API_KEY or not GOOGLE_API_KEY.strip():
        return "‚ö†Ô∏è Google API Key ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh."
    
    try:
        img = Image.open(io.BytesIO(image_bytes))
        model_ai = genai.GenerativeModel('gemini-1.5-pro-latest')
        
        prompt_parts = [
            "B·∫°n l√† m·ªôt chuy√™n gia ch·∫©n ƒëo√°n b·ªánh c√¢y tr·ªìng qua h√¨nh ·∫£nh. H√£y ph√¢n t√≠ch k·ªπ l∆∞·ª°ng ·∫£nh l√° c√† chua n√†y.\n",
            "1. Ch·∫©n ƒëo√°n xem l√° c√¢y b·ªã b·ªánh g√¨ ho·∫∑c l√† l√° kh·ªèe m·∫°nh.\n",
            "2. Li·ªát k√™ c√°c tri·ªáu ch·ª©ng c·ª• th·ªÉ b·∫°n nh√¨n th·∫•y tr√™n l√° (v√≠ d·ª•: ƒë·ªëm v√†ng, vi·ªÅn n√¢u, l√° quƒÉn...).\n",
            "3. ƒê∆∞a ra k·∫øt lu·∫≠n m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch.\n\n",
            img,
        ]
        
        response = model_ai.generate_content(prompt_parts)
        return f"**ƒê√°nh gi√° t·ª´ Google Gemini Vision:**\n\n" + response.text
    except Exception as e:
        return f"‚ùå L·ªói khi g·ªçi API Google Gemini Vision: {str(e)}"

# UI
st.title("üçÖ Tr·ª£ l√Ω C√† chua AI")
st.markdown("*Ph√¢n lo·∫°i b·ªánh c√† chua b·∫±ng AI - Phi√™n b·∫£n Production*")

with st.sidebar:
    st.header("üìñ Th∆∞ vi·ªán b·ªánh h·ªçc")
    selected_disease = st.selectbox("Tra c·ª©u th√¥ng tin b·ªánh:", list(DISEASE_LIBRARY.keys()))
    
    if selected_disease:
        info = DISEASE_LIBRARY[selected_disease]
        st.subheader(selected_disease)
        st.markdown(f"**M√¥ t·∫£:** {info['description']}")
        st.markdown(f"**Tri·ªáu ch·ª©ng:**\n{info['symptoms']}")
    
    st.markdown("---")
    st.header("üìú L·ªãch s·ª≠ nh·∫≠n di·ªán")
    
    if not st.session_state.history:
        st.info("Ch∆∞a c√≥ l·ªãch s·ª≠ n√†o.")
    else:
        for i in range(len(st.session_state.history) - 1, -1, -1):
            record = st.session_state.history[i]
            col1, col2 = st.columns([4, 1])
            
            with col1:
                with st.expander(f"{record['prediction']} ({record['time']})"):
                    st.image(record['image'], width=100)
                    st.write(f"ƒê·ªô tin c·∫≠y: {record['confidence']:.2f}%")
            
            with col2:
                if st.button("üóëÔ∏è", key=f"delete_{i}_{record['time']}", help="X√≥a m·ª•c n√†y"):
                    del st.session_state.history[i]
                    st.rerun()

col1, col2 = st.columns([2, 3])

with col1:
    st.subheader("‚ë† T·∫£i ho·∫∑c Ch·ª•p ·∫£nh")
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh t·ª´ thi·∫øt b·ªã:", type=["jpg", "jpeg", "png"])
    camera_file = st.camera_input("Ch·ª•p ·∫£nh t·ª´ camera:")
    
    image_to_process = camera_file or uploaded_file
    if image_to_process:
        st.image(image_to_process, caption="·∫¢nh ƒë∆∞·ª£c ch·ªçn", use_container_width=True)

with col2:
    st.subheader("‚ë° Xem k·∫øt qu·∫£ ph√¢n t√≠ch")
    
    if image_to_process and model is not None:
        with st.spinner("‚è≥ AI ƒëang ph√¢n t√≠ch, vui l√≤ng ch·ªù..."):
            predicted_class, confidence, probabilities = predict_image(image_to_process)
            result_image = draw_result(image_to_process, predicted_class, confidence)
        
        current_time = datetime.now().strftime("%H:%M:%S")
        new_record = {
            "image": image_to_process.getvalue(),
            "prediction": predicted_class,
            "confidence": confidence,
            "time": current_time
        }
        
        if not st.session_state.history or st.session_state.history[-1]['prediction'] != new_record['prediction']:
            st.session_state.history.append(new_record)
        
        if len(st.session_state.history) > 10:
            st.session_state.history.pop(0)
        
        tabs = st.tabs(["üìä K·∫øt qu·∫£ ch√≠nh", "‚ÜîÔ∏è So s√°nh ·∫£nh", "üßë‚Äçüåæ T∆∞ v·∫•n AI (Groq)", "üîç Ki·ªÉm tra ch√©o (Gemini)"])
        
        with tabs[0]:
            st.metric("Ch·∫©n ƒëo√°n (Model T·ª± hu·∫•n luy·ªán)", predicted_class)
            st.metric("ƒê·ªô tin c·∫≠y", f"{confidence:.2f}%")
            st.markdown("---")
            st.markdown("##### Ph√¢n b·ªï x√°c su·∫•t:")
            
            for cls, prob in zip(class_names, probabilities):
                st.write(f"{cls}: {prob*100:.2f}%")
                st.progress(float(prob))
            
            buf = io.BytesIO()
            result_image.save(buf, format="PNG")
            st.download_button("‚¨áÔ∏è T·∫£i ·∫£nh k·∫øt qu·∫£", buf.getvalue(), "ket_qua.png", "image/png")
        
        with tabs[1]:
            st.markdown("K√©o thanh tr∆∞·ª£t ƒë·ªÉ so s√°nh.")
            image_comparison(Image.open(image_to_process), result_image, "·∫¢nh g·ªëc", "·∫¢nh c√≥ ch·∫©n ƒëo√°n")
        
        with tabs[2]:
            st.info("Nh·∫≠n g·ª£i √Ω chi ti·∫øt t·ª´ AI LLaMA 3.1 qua Groq.")
            if st.button("üí° Nh·∫≠n g·ª£i √Ω tr·ªã b·ªánh"):
                with st.spinner("ü§ñ Groq AI ƒëang so·∫°n th·∫£o..."):
                    st.markdown(get_treatment_suggestion(predicted_class))
        
        with tabs[3]:
            st.info("S·ª≠ d·ª•ng Google Gemini Vision ƒë·ªÉ c√≥ th√™m g√≥c nh√¨n th·ª© hai.")
            if st.button("üî¨ B·∫Øt ƒë·∫ßu ki·ªÉm tra ch√©o v·ªõi Gemini"):
                with st.spinner("üõ∞Ô∏è Gemini Vision ƒëang ph√¢n t√≠ch ·∫£nh..."):
                    st.markdown(get_vision_ai_check(image_to_process.getvalue()))
    
    elif image_to_process and model is None:
        st.error("‚ùå Model ch∆∞a ƒë∆∞·ª£c t·∫£i. Vui l√≤ng ki·ªÉm tra file model.")
    else:
        st.info("üëà Vui l√≤ng t·∫£i ·∫£nh l√™n ho·∫∑c s·ª≠ d·ª•ng camera ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

# Footer
st.markdown("---")
st.markdown("**üçÖ Tomato Disease AI Assistant** - Powered by TensorFlow & Streamlit")