import streamlit as st
import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np
import os
from PIL import Image, ImageDraw, ImageFont
import io
from streamlit_image_comparison import image_comparison
from groq import Groq
from datetime import datetime
import google.generativeai as genai

st.set_page_config(page_title="Trá»£ lÃ½ CÃ  chua AI", page_icon="ğŸ…", layout="wide")

# API Keys tá»« Streamlit Secrets vá»›i error handling
try:
    GROQ_API_KEY = st.secrets.get("GROQ_API_KEY", "")
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", "")
except Exception as e:
    st.error(f"âŒ Lá»—i Ä‘á»c secrets: {e}")
    GROQ_API_KEY = ""
    GOOGLE_API_KEY = ""

# Initialize Groq client vá»›i error handling
groq_client = None
if GROQ_API_KEY and GROQ_API_KEY.strip():
    try:
        groq_client = Groq(api_key=GROQ_API_KEY.strip())
    except Exception as e:
        st.sidebar.error(f"âŒ Lá»—i Groq: {e}")
        groq_client = None
else:
    st.sidebar.warning("âš ï¸ Groq API chÆ°a cáº¥u hÃ¬nh")

# Initialize Google AI vá»›i error handling
if GOOGLE_API_KEY and GOOGLE_API_KEY.strip():
    try:
        genai.configure(api_key=GOOGLE_API_KEY.strip())
    except Exception as e:
        st.sidebar.error(f"âŒ Lá»—i Google AI: {e}")
else:
    st.sidebar.warning("âš ï¸ Google API chÆ°a cáº¥u hÃ¬nh")

DISEASE_LIBRARY = {
    'Bá»‡nh: Nhá»‡n Ä‘á» (spider mites)': {
        'description': 'Nhá»‡n Ä‘á» ráº¥t nhá», sá»‘ng á»Ÿ máº·t dÆ°á»›i lÃ¡, hÃºt nhá»±a cÃ¢y, lÃ m lÃ¡ cÃ³ Ä‘á»‘m vÃ ng, báº¡c.',
        'symptoms': '- LÃ¡ cÃ³ cháº¥m li ti vÃ ng/tráº¯ng.\n- CÃ³ thá»ƒ cÃ³ máº¡ng nhá»‡n má»‹n máº·t dÆ°á»›i lÃ¡.'
    },
    'Bá»‡nh: SÆ°Æ¡ng mai (late blight)': {
        'description': 'Bá»‡nh nguy hiá»ƒm do náº¥m, phÃ¡t triá»ƒn máº¡nh khi áº©m, mÃ¡t.',
        'symptoms': '- Äá»‘m xanh xÃ¡m, Ãºng nÆ°á»›c trÃªn lÃ¡.\n- Váº¿t bá»‡nh lan nhanh, chuyá»ƒn mÃ u nÃ¢u Ä‘en.'
    },
    'Bá»‡nh: Äá»‘m má»¥c tiÃªu (target spot)': {
        'description': 'Bá»‡nh do náº¥m gÃ¢y ra, táº¡o thÃ nh cÃ¡c Ä‘á»‘m trÃ²n cÃ³ vÃ²ng trÃ²n Ä‘á»“ng tÃ¢m.',
        'symptoms': '- Äá»‘m trÃ²n mÃ u nÃ¢u cÃ³ vÃ²ng trÃ²n.\n- LÃ¡ vÃ ng vÃ  rá»¥ng sá»›m.'
    },
    'LÃ¡ khá»e máº¡nh': {
        'description': 'LÃ¡ khÃ´ng cÃ³ dáº¥u hiá»‡u bá»‡nh, mÃ u xanh Ä‘á»u.',
        'symptoms': '- Bá» máº·t lÃ¡ nháºµn, khÃ´ng Ä‘á»‘m, má»‘c.\n- MÃ u sáº¯c xanh tÆ°Æ¡i.'
    },
    'Bá»‡nh: QuÄƒn lÃ¡ (leaf curl)': {
        'description': 'Bá»‡nh do virus gÃ¢y ra, lÃ m lÃ¡ quÄƒn cong vÃ  biáº¿n dáº¡ng.',
        'symptoms': '- LÃ¡ quÄƒn cong báº¥t thÆ°á»ng.\n- MÃ u lÃ¡ nháº¡t, vÃ ng Ãºa.'
    },
    'Bá»‡nh: Äá»‘m septoria': {
        'description': 'Bá»‡nh do náº¥m Septoria lycopersici, thÆ°á»ng xuáº¥t hiá»‡n á»Ÿ lÃ¡ giÃ .',
        'symptoms': '- Äá»‘m trÃ²n nhá» mÃ u xÃ¡m vá»›i viá»n Ä‘en.\n- LÃ¡ vÃ ng vÃ  rá»¥ng tá»« dÆ°á»›i lÃªn.'
    },
    'Bá»‡nh: Má»‘c lÃ¡ (leaf mold)': {
        'description': 'Bá»‡nh do náº¥m, phÃ¡t triá»ƒn trong Ä‘iá»u kiá»‡n áº©m Æ°á»›t.',
        'symptoms': '- Lá»›p má»‘c vÃ ng á»Ÿ máº·t dÆ°á»›i lÃ¡.\n- LÃ¡ hÃ©o vÃ  cháº¿t dáº§n.'
    },
    'Bá»‡nh: SÆ°Æ¡ng mai sá»›m (early blight)': {
        'description': 'Bá»‡nh do náº¥m Alternaria solani, áº£nh hÆ°á»Ÿng Ä‘áº¿n lÃ¡ vÃ  quáº£.',
        'symptoms': '- Äá»‘m nÃ¢u cÃ³ vÃ²ng trÃ²n Ä‘á»“ng tÃ¢m.\n- LÃ¡ vÃ ng vÃ  rá»¥ng sá»›m.'
    }
}

if 'history' not in st.session_state:
    st.session_state.history = []

@st.cache_resource
def load_keras_model():
    """Load model tá»« GitHub hoáº·c local"""
    # Thay Ä‘á»•i path model cho production
    model_path = "models/keras_model.h5"
    
    # Check if model exists before loading
    if not os.path.exists(model_path):
        st.error(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh táº¡i {model_path}")
        st.info("ğŸ’¡ Vui lÃ²ng upload file model vÃ o thÆ° má»¥c 'models/' vá»›i tÃªn 'keras_model.h5'")
        st.stop()
    
    def custom_depthwise_conv2d(*args, **kwargs):
        kwargs.pop('groups', None)
        return tf.keras.layers.DepthwiseConv2D(*args, **kwargs)
    
    try:
        model = tf.keras.models.load_model(
            model_path, 
            custom_objects={'DepthwiseConv2D': custom_depthwise_conv2d}, 
            compile=False
        )
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        return model
    except Exception as e:
        st.error(f"âŒ Lá»—i khi táº£i mÃ´ hÃ¬nh: {e}")
        st.stop()

# Chá»‰ load model khi cÃ³ file
if os.path.exists("models/keras_model.h5"):
    model = load_keras_model()
    class_names = [
        'Bá»‡nh: Nhá»‡n Ä‘á» (spider mites)', 
        'Bá»‡nh: SÆ°Æ¡ng mai (late blight)', 
        'Bá»‡nh: Äá»‘m má»¥c tiÃªu (target spot)', 
        'LÃ¡ khá»e máº¡nh', 
        'Bá»‡nh: QuÄƒn lÃ¡ (leaf curl)', 
        'Bá»‡nh: Äá»‘m septoria', 
        'Bá»‡nh: Má»‘c lÃ¡ (leaf mold)', 
        'Bá»‡nh: SÆ°Æ¡ng mai sá»›m (early blight)'
    ]
else:
    model = None
    st.error("âŒ Model chÆ°a Ä‘Æ°á»£c upload. Vui lÃ²ng thÃªm file 'keras_model.h5' vÃ o thÆ° má»¥c 'models/'")

def predict_image(image):
    if model is None:
        return "Model chÆ°a Ä‘Æ°á»£c táº£i", 0, []
    
    img = load_img(image, target_size=(224, 224))
    img_array = img_to_array(img) / 127.5 - 1
    img_array = np.expand_dims(img_array, axis=0)
    predictions = model.predict(img_array)
    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = np.max(predictions[0]) * 100
    return predicted_class, confidence, predictions[0]

def draw_result(image_file, result_text, confidence):
    image = Image.open(image_file).convert("RGB")
    draw = ImageDraw.Draw(image)
    
    try:
        font = ImageFont.truetype("arial.ttf", 30)
    except IOError:
        font = ImageFont.load_default()
    
    text = f"{result_text} ({confidence:.2f}%)"
    text_bbox = draw.textbbox((0, 0), text, font=font)
    text_width = text_bbox[2] - text_bbox[0]
    text_height = text_bbox[3] - text_bbox[1]
    
    draw.rectangle([(10, 10), (10 + text_width + 20, 10 + text_height + 20)], fill="rgba(0,0,0,128)")
    draw.text((20, 20), text, fill="white", font=font)
    return image

@st.cache_data
def get_treatment_suggestion(disease_name: str) -> str:
    if not groq_client:
        return "âš ï¸ Groq API chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh hoáº·c cÃ³ lá»—i káº¿t ná»‘i."
    
    if disease_name == 'LÃ¡ khá»e máº¡nh':
        return "âœ… Tuyá»‡t vá»i! LÃ¡ cÃ¢y cá»§a báº¡n khá»e máº¡nh."
    
    try:
        response = groq_client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": "Báº¡n lÃ  chuyÃªn gia nÃ´ng nghiá»‡p Viá»‡t Nam, tÆ° váº¥n cÃ¡ch trá»‹ bá»‡nh cÃ  chua ngáº¯n gá»n cho nÃ´ng dÃ¢n."},
                {"role": "user", "content": f"CÃ¢y cÃ  chua cá»§a tÃ´i bá»‹ '{disease_name}'. Äá» xuáº¥t phÆ°Æ¡ng phÃ¡p trá»‹ vÃ  phÃ²ng bá»‡nh."}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ Lá»—i API tÆ° váº¥n: {str(e)}"

def get_vision_ai_check(image_bytes: bytes) -> str:
    if not GOOGLE_API_KEY or not GOOGLE_API_KEY.strip():
        return "âš ï¸ Google API Key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh."
    
    try:
        img = Image.open(io.BytesIO(image_bytes))
        model_ai = genai.GenerativeModel('gemini-1.5-pro-latest')
        
        prompt_parts = [
            "Báº¡n lÃ  má»™t chuyÃªn gia cháº©n Ä‘oÃ¡n bá»‡nh cÃ¢y trá»“ng qua hÃ¬nh áº£nh. HÃ£y phÃ¢n tÃ­ch ká»¹ lÆ°á»¡ng áº£nh lÃ¡ cÃ  chua nÃ y.\n",
            "1. Cháº©n Ä‘oÃ¡n xem lÃ¡ cÃ¢y bá»‹ bá»‡nh gÃ¬ hoáº·c lÃ  lÃ¡ khá»e máº¡nh.\n",
            "2. Liá»‡t kÃª cÃ¡c triá»‡u chá»©ng cá»¥ thá»ƒ báº¡n nhÃ¬n tháº¥y trÃªn lÃ¡ (vÃ­ dá»¥: Ä‘á»‘m vÃ ng, viá»n nÃ¢u, lÃ¡ quÄƒn...).\n",
            "3. ÄÆ°a ra káº¿t luáº­n má»™t cÃ¡ch ngáº¯n gá»n, sÃºc tÃ­ch.\n\n",
            img,
        ]
        
        response = model_ai.generate_content(prompt_parts)
        return f"**ÄÃ¡nh giÃ¡ tá»« Google Gemini Vision:**\n\n" + response.text
    except Exception as e:
        return f"âŒ Lá»—i khi gá»i API Google Gemini Vision: {str(e)}"

# UI
st.title("ğŸ… Trá»£ lÃ½ CÃ  chua AI")
st.markdown("*PhÃ¢n loáº¡i bá»‡nh cÃ  chua báº±ng AI - PhiÃªn báº£n Production*")

with st.sidebar:
    st.header("ğŸ“– ThÆ° viá»‡n bá»‡nh há»c")
    selected_disease = st.selectbox("Tra cá»©u thÃ´ng tin bá»‡nh:", list(DISEASE_LIBRARY.keys()))
    
    if selected_disease:
        info = DISEASE_LIBRARY[selected_disease]
        st.subheader(selected_disease)
        st.markdown(f"**MÃ´ táº£:** {info['description']}")
        st.markdown(f"**Triá»‡u chá»©ng:**\n{info['symptoms']}")
    
    st.markdown("---")
    st.header("ğŸ“œ Lá»‹ch sá»­ nháº­n diá»‡n")
    
    if not st.session_state.history:
        st.info("ChÆ°a cÃ³ lá»‹ch sá»­ nÃ o.")
    else:
        for i in range(len(st.session_state.history) - 1, -1, -1):
            record = st.session_state.history[i]
            col1, col2 = st.columns([4, 1])
            
            with col1:
                with st.expander(f"{record['prediction']} ({record['time']})"):
                    st.image(record['image'], width=100)
                    st.write(f"Äá»™ tin cáº­y: {record['confidence']:.2f}%")
            
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"delete_{i}_{record['time']}", help="XÃ³a má»¥c nÃ y"):
                    del st.session_state.history[i]
                    st.rerun()

col1, col2 = st.columns([2, 3])

with col1:
    st.subheader("â‘  Táº£i hoáº·c Chá»¥p áº£nh")
    uploaded_file = st.file_uploader("Táº£i áº£nh tá»« thiáº¿t bá»‹:", type=["jpg", "jpeg", "png"])
    camera_file = st.camera_input("Chá»¥p áº£nh tá»« camera:")
    
    image_to_process = camera_file or uploaded_file
    if image_to_process:
        st.image(image_to_process, caption="áº¢nh Ä‘Æ°á»£c chá»n", use_container_width=True)

with col2:
    st.subheader("â‘¡ Xem káº¿t quáº£ phÃ¢n tÃ­ch")
    
    if image_to_process and model is not None:
        with st.spinner("â³ AI Ä‘ang phÃ¢n tÃ­ch, vui lÃ²ng chá»..."):
            predicted_class, confidence, probabilities = predict_image(image_to_process)
            result_image = draw_result(image_to_process, predicted_class, confidence)
        
        current_time = datetime.now().strftime("%H:%M:%S")
        new_record = {
            "image": image_to_process.getvalue(),
            "prediction": predicted_class,
            "confidence": confidence,
            "time": current_time
        }
        
        if not st.session_state.history or st.session_state.history[-1]['prediction'] != new_record['prediction']:
            st.session_state.history.append(new_record)
        
        if len(st.session_state.history) > 10:
            st.session_state.history.pop(0)
        
        tabs = st.tabs(["ğŸ“Š Káº¿t quáº£ chÃ­nh", "â†”ï¸ So sÃ¡nh áº£nh", "ğŸ§‘â€ğŸŒ¾ TÆ° váº¥n AI (Groq)", "ğŸ” Kiá»ƒm tra chÃ©o (Gemini)"])
        
        with tabs[0]:
            st.metric("Cháº©n Ä‘oÃ¡n (Model Tá»± huáº¥n luyá»‡n)", predicted_class)
            st.metric("Äá»™ tin cáº­y", f"{confidence:.2f}%")
            st.markdown("---")
            st.markdown("##### PhÃ¢n bá»• xÃ¡c suáº¥t:")
            
            for cls, prob in zip(class_names, probabilities):
                st.write(f"{cls}: {prob*100:.2f}%")
                st.progress(float(prob))
            
            buf = io.BytesIO()
            result_image.save(buf, format="PNG")
            st.download_button("â¬‡ï¸ Táº£i áº£nh káº¿t quáº£", buf.getvalue(), "ket_qua.png", "image/png")
        
        with tabs[1]:
            st.markdown("KÃ©o thanh trÆ°á»£t Ä‘á»ƒ so sÃ¡nh.")
            image_comparison(Image.open(image_to_process), result_image, "áº¢nh gá»‘c", "áº¢nh cÃ³ cháº©n Ä‘oÃ¡n")
        
        with tabs[2]:
            st.info("Nháº­n gá»£i Ã½ chi tiáº¿t tá»« AI LLaMA 3.1 qua Groq.")
            if st.button("ğŸ’¡ Nháº­n gá»£i Ã½ trá»‹ bá»‡nh"):
                with st.spinner("ğŸ¤– Groq AI Ä‘ang soáº¡n tháº£o..."):
                    st.markdown(get_treatment_suggestion(predicted_class))
        
        with tabs[3]:
            st.info("Sá»­ dá»¥ng Google Gemini Vision Ä‘á»ƒ cÃ³ thÃªm gÃ³c nhÃ¬n thá»© hai.")
            if st.button("ğŸ”¬ Báº¯t Ä‘áº§u kiá»ƒm tra chÃ©o vá»›i Gemini"):
                with st.spinner("ğŸ›°ï¸ Gemini Vision Ä‘ang phÃ¢n tÃ­ch áº£nh..."):
                    st.markdown(get_vision_ai_check(image_to_process.getvalue()))
    
    elif image_to_process and model is None:
        st.error("âŒ Model chÆ°a Ä‘Æ°á»£c táº£i. Vui lÃ²ng kiá»ƒm tra file model.")
    else:
        st.info("ğŸ‘ˆ Vui lÃ²ng táº£i áº£nh lÃªn hoáº·c sá»­ dá»¥ng camera Ä‘á»ƒ báº¯t Ä‘áº§u.")

# Footer
st.markdown("---")
st.markdown("**ğŸ… Tomato Disease AI Assistant** - Powered by TensorFlow & Streamlit")